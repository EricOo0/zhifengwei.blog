# SQL&&Redis  

* 结构：  

>应用层：连接处理--连接池，用户鉴权，安全处理
MySQL服务层：提供数据管理，sql解释，优化等
存储引擎层：实际存储数据的系统
* Sql搜索可以考虑的数据结构

>目标：高效，快速  
哈希表：O（1）的处理速度，单点搜索快但是不适合范围查找，排序  
二叉树：O（logn）的时间复杂度，天然的排序特性，但容易不平衡  
AVL：严格平衡但是旋转耗时且IO消耗较大，如果深的话（一次查找一个值，进行一次IO）  
B树：有序数组+平衡多叉树；  
每个子节点可以存放多个值，树深度降低，适合查找  
B+树：有序数组链表+平衡多叉树  
每个子节点不存放值，只存放索引（地址），在叶子节点存放所有的数据，且用链表链接所有叶子节点（更适合范围查找，减少磁盘IO次数），每次查询需要的次数是一样的  

* 四大特性：  

>ACID:原子性atomic，一致性consistency，隔离性：isolation，持久性duration  
原子性：利用undo_log；失败回滚  
持久性：redo_log和刷入磁盘持久化  
隔离性：加锁和mvcc  

* 事务实现：
>事务的实现依靠redo log：数据库的操作先写到缓存中和redo log buffer里，commit后同步到数据库中，实现持久化

* 三大范式:  

>第一范式：字段不可再拆分成子字段  
第二范式：各字段都和主键有联系  
第三范式：各字段只和主键有全部联系（只依赖于主键）  
* 五大约束：  

>唯一约束：unique  
主键约束 primary  
外键约束:foreign  
默认约束：default  
非空约束：notnull    
* 索引类型  

>1.普通索引  
2.唯一索引 ：索引列的值必须唯一 ，允许null！  
3.主键索引 ：一个表只能有一个主键，不允许有空值  
4.组合索引  
5.全文索引  

* 聚蔟索引和非聚蔟索引  
> 聚蔟索引：将数据存储与索引放到了一块，找到索引也就找到了数据，一般主键就是聚蔟索引，叶子节点存放了数据；只有一个  
非聚蔟索引：又叫二级索引，辅助索引，叶子节点存储的是主键的值  
聚蔟索引是innodb的特性，mysiam没有，如果需要使用聚蔟索引，设置主键即可，如果没有主键，会用一个唯一且非空的列为主键，也没有的话innodb会创建一个虚拟主键   

* 数据库回表  
通过辅助索引(非聚蔟索引)，找到主键，在查询表中数据的过程叫回表，如果只需要辅助索引的键值，则不需要回表--这种是覆盖索引  

* 不走索引的情况

>对索引列使用函数  
or的列有的没有建立索引--可以用union查询
索引列是string却用int去查询，(int 可以用 char查询)
联合索引不满足最左匹配 a/ab/abc abc只走a
* 数据库索引：加快检索表中数据的方法  
* Mysql索引：  
       
>索引可以提高检索速度但会降低更新速度，需要更新索引文件  
* Mysql主要包含四种隔离状态  

>读未提交Read Uncommitted：脏读-在该隔离级别，所有事务都可以看到其他未提交事务的执行结果。  
读取提交内容Read committed：一个事务只能看见已经提交事务所做的改变  
可重复读 ：幻读，提交前读取的数据不变  
串行化  

* 数据库事务隔离：  

>同一时间，只允许一个事务请求同一数据，不同的事务之间彼此没有任何干扰。比如A正在从一张银行卡中取钱，在A取钱的过程结束前，B不能向这张卡转账。  
*  mysql有哪几种锁
>myisam支持表级锁  
innodb支持行锁  
读锁写锁（或者叫排他锁共享锁）
间隙锁


* MVCC理解
>1、什么是MVCC？
    多版本并发控制
    https://juejin.cn/post/6871046354018238472
    https://juejin.cn/post/6844903986143690765
2、实现方式？
事务隔离实现两种方式一种是加读写锁(串行化)，另一种就是MVCC.
MVCC主要是通过在每一行记录中增加三个字段，与 undo log 中相关记录配合使用，同时加上可见性算法，使得各个事务可以在不加锁的情况下能够同时地读取到某行记录上的准确值（这个值对不同的事务而言可能是不同的）。使用 MVCC，在不加锁的情况下也能读取到准确的数据，大大提高了并发效率。
>>1、对于数据库中的每条数据，添加三个字段（trx_id;roll_ptr;row_id）
2、当事务对数据进行更新时，会将操作写入undo log，并且更新数据的trx_id和roll_ptr
3、当事务进行查询的时候，通过roll_ptr去找到当前事务能读到的最近历史版本的数据(比较trx_id和read_view)
关键:
roll_ptr--**版本链**
**undo日志**
**read_view**
>>>read_view-一致性视图
用于可见性判断，事务在创建的时候会生成一个快照，由下列4个部分组成：
creator_trx_id:当前事务id
m_ids:所有事务的事务id
min_trx_id:m_ids里最小的事务id值
max_trx_id:最大事务id
如果是已提交读，那么每一个语句执行前都会重新算出一个新的视图，如果是可重复读，则是执行事务时创建
四种隔离级别，只有「读提交」和「可重复度」两个隔离级别能够使用 MVCC，因此也只有这两个隔离级别会创建一致性视图（read-view）
可重复读会带来幻读的问题，可通过间隙锁解决 select ... for update
* 权限设置：  

>通过用户名密码登录到账户  
Grand 权限（update，drop等）on 表 to 用户  
Revoke 撤销权限  
* 存储引擎：负责数据库中的数据的存储和查提取。使用不同的技术将数据存储在

>文件或内存中(不同的表结构)；show engine看存储引擎  
Myisam：不支持事务，（基于hash）但是插入数据快，适合在插入或选择密集（读或写的多单一业务）数据库，对硬件要求低，表锁：不会发生锁冲突  
Innodb：支持事务，支持事务提交和回滚，加入外键约束，适合多重并发（更新密集）的数据库，行锁：容易死锁  
Memory：运行在内存上，速度快但容易丢失，不支持事务  

![image text](https://github.com/EricOo0/my_repo/blob/88853547c0b5a73f8ecd1492103a8e32f2dbd88c/Image/innodb.jpg)

* sql分区：  

>MySQL在创建表的时候可以通过使用PARTITION BY子句定义每个分区存放的数据。在执行查询的时候，优化器根据分区定义过滤那些没有我们需要的数据的分区，这样查询就可以无需扫描所有分区，只需要查找包含需要数据的分区即可。  
create TABLE tblname (upload_date string,FTarget string) PARTITION BY RANGE (upload_date) (partition p_20210615 values less than (20210615) )  
常用分区类型：range；list
查看某个分区信息：  
show create table partition_test；查看创建表的语句  
show table status；看表是不是分区表  
information_schema.PARTITIONS 存储分区信息，可以去这张表查    
SELECT * FROM tr p2;查看这个分区的信息    
alter table partition_test add partition  (partition p_20210616 values less than (20210616));增加分区  
* Mysql主从一致：  
>从库复制主库的binlog日志，执行日志命令来复制（两个线程）  
1、主从同步作用：  
        从服务器起备份作用；  
        主服务器挂掉的时候，从服务器可以起作用；  
        可以用来做读写分离  
2、分工-流程：  
        主数据服务器：主要用来从业务服务写入数据或者修改更新数据。  
        从数据服务器：主要用来读取业务所需要的数据  
        二进制日志：用来存储写入以及更新的数据信息  
        中继日志：承接主服务器数据信息，转存在从服务器上  
        I/O线程：监听主服务器是否发生数据更改的行为  
        SQL线程：将主服务器数据更改的数据从中继日志文件中读取数据写入到从数据服务器中
当主数据服务器master进行写入数据或者更新数据操作的时候，数据更改会记录在二进制日志（binary log file）中，主服务器master与从服务器slave进行通讯的是I/O线程，它将修改的数据异步复制写入到slave服务器的中继日志（relay log file）中,从服务器slave与中继日志之间通信使用SQL线程，SQL线程可以异步从中继日志中读取数据后再写入到自己的数据库中，就完成了数据的主从同步功能。  

![master-slave](https://github.com/EricOo0/my_repo/blob/master/Image/master-slave.png)

* Mysql回滚  
>使用begin开始一个事务，在commit之前可以回滚rollback  
* 连接池：
>数据库连接池负责分配、管理和释放数据库连接，它允许应用程序重复使用一个现有的数据库连接，而不是再重新建立一个  
一个数据库连接对象均对应一个物理数据库连接，每次操作都打开一个物理连接，使用完都关闭连接，这样造成系统的性能低下。  
数据库连接池的解决方案是在应用程序启动时建立足够的数据库连接，并讲这些连接组成一个连接池(简单说：在一个“池”里放了好多半成品的数据库联接对象)  
1\程序初始化时创建连接池    
2\使用时向连接池申请可用连接  
3\使用完毕，将连接返还给连接池  
4\程序退出时，断开连接，并释放资源  
* 存储过程：  
>预先通过编译和存储在数据库的一段sql命令集合  
* 绑定变量
>减少解析次数，提高效率  
* redis:  
    
>非关系型数据库，是单线程的结构型数据存储(key-value)，用C实现的  
模型：IO多路复用+单线程  
用SET和GET设置和获取数据  
支持五种数据结构：  
key:string字符串  value: string list hashmap set zset（有序集合）等   
string --sds，自动记录字符串长度
list--双端链表实现  lpush rpush lrange  
哈希表--数组+链表实现；解决哈希冲突：链表发，新节点加到头--rehash；hset，hget；key和value交替填入  
set--集合sadd添加spop弹出；  
zset--有序列表：用跳表实现  
持久化方式：  
    RDB和AOF  
    RDB简而言之，就是在不同的时间点，将 redis 存储的数据生成快照并存储到磁盘等介质上；   
    AOF 方式是将执行过的写指令记录下来，在数据恢复时按照从前到后的顺序再将指令都执行一遍，  
支持主从复制，读写分离  
* 内存管理机制上：  
>Redis 数据全部存在内存，定期写入磁盘，当内存不够时，可以选择指定的 LRU（最少使用） 算法删除数据  

* 位图和布隆过滤器
>面对海量数据的去重和过滤问题，系统内存不够，可以考虑使用位图和布隆过滤器解决：  
1、布隆过滤器：可用来检查数据可能在集合中或者一定不在集合中  
使用一个长度为m的向量或位列表，初始值全为0  
为了将数据插入列表，提供了k个哈希散列函数(输出为单个索引值)，每个数据通过哈希函数得到k个索引，将k个索引位置1  

![bloom](https://github.com/EricOo0/zhifengwei.blog/blob/main/Image/boolen.png)  

>判断元素是否存在集合中，k个索引位都为1--可能存在误判
应用：数据去重；缓解缓存穿透  
2、位图：每一个bit代表一个数据，用一个bit数据来记录数据可以减少内存使用  
如果用一个int数组存储：int  a[N]--可以记录N*4*8个数据
数据记录：num/32=第几个字节  num%32=该字节的第几位
数据判断：判断对应的字节和位是否为1
问题：bitmap的大小和存储的最大数据有关，如果数据很大但量很小会浪费空间